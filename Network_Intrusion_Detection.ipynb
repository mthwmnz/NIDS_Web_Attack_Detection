{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkfDaXESnGvN"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/pycaret/pycaret.git@master --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvseSbc_o2hc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pycaret.classification import *\n",
        "\n",
        "# --- 1. Load Your Specific Dataset ---\n",
        "filename = 'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv'\n",
        "print(f\"--- 1. Loading Dataset: {filename} ---\")\n",
        "\n",
        "try:\n",
        "    # Use 'low_memory=False' AND specify encoding='latin1'\n",
        "    data = pd.read_csv(filename, low_memory=False, encoding='latin1')\n",
        "    print(\"--- Dataset Loaded Successfully ---\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"!!! ERROR: File '{filename}' not found. Did you upload it to Colab?\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"!!! An error occurred during loading: {e}\")\n",
        "    raise\n",
        "\n",
        "# --- 2. Data Preprocessing (CRITICAL) ---\n",
        "print(\"--- 2. Preprocessing Data ---\")\n",
        "\n",
        "# a. Clean column names\n",
        "data.columns = data.columns.str.strip()\n",
        "\n",
        "# b. Convert columns to numeric, coercing errors to NaN\n",
        "print(\"   - Converting columns to numbers (errors become NaN)...\")\n",
        "numeric_cols = data.columns.drop(['Label', 'Timestamp'], errors='ignore') # Get columns except Label/Timestamp\n",
        "data[numeric_cols] = data[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# c. Replace Inf values with NaN\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "print(\"   - Replaced Inf with NaN.\")\n",
        "\n",
        "# d. Create the binary target variable 'Anomaly'\n",
        "# Make sure 'Label' column exists before proceeding\n",
        "if 'Label' in data.columns:\n",
        "    attack_labels = data['Label'].unique()[data['Label'].unique() != 'BENIGN']\n",
        "    data['Anomaly'] = data['Label'].apply(lambda x: 1 if x in attack_labels else 0)\n",
        "    print(\"   - Created 'Anomaly' target column.\")\n",
        "else:\n",
        "     print(\"!!! ERROR: 'Label' column not found after loading. Check the CSV.\")\n",
        "     raise ValueError(\"Missing 'Label' column\")\n",
        "\n",
        "# e. Drop original columns we don't need for training\n",
        "# Ensure 'Timestamp' column exists before dropping, handle if not present\n",
        "columns_to_drop = ['Label']\n",
        "if 'Timestamp' in data.columns:\n",
        "    columns_to_drop.append('Timestamp')\n",
        "data.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# --- DO NOT DROPNA HERE ---\n",
        "# Instead, check how many NaNs we created\n",
        "nan_counts = data.isna().sum()\n",
        "print(f\"   - NaN values created during conversion:\\n{nan_counts[nan_counts > 0]}\") # Show columns with NaNs\n",
        "\n",
        "print(\"--- Preprocessing Complete ---\")\n",
        "print(\"Attack (1) vs. Benign (0) counts in this file (before setup imputation):\")\n",
        "# Check if 'Anomaly' column exists before value_counts\n",
        "if 'Anomaly' in data.columns:\n",
        "    print(data['Anomaly'].value_counts())\n",
        "else:\n",
        "    print(\"!!! ERROR: 'Anomaly' column not created. Check 'Label' column processing.\")\n",
        "    raise ValueError(\"Missing 'Anomaly' column\")\n",
        "\n",
        "\n",
        "# --- 3. Setup the PyCaret Environment ---\n",
        "print(\"\\n--- 3. Setting up PyCaret Experiment ---\")\n",
        "# PyCaret's setup will now handle the NaN values automatically (default is mean imputation)\n",
        "clf_setup = setup(\n",
        "    data=data,\n",
        "    target='Anomaly',\n",
        "    session_id=123,\n",
        "    fix_imbalance=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "# --- 4. Compare Models for Your Project ---\n",
        "print(\"\\n--- 4. Comparing Models ---\")\n",
        "best_model = compare_models(sort='F1')\n",
        "\n",
        "\n",
        "# --- 5. Create the Specific Models You Need ---\n",
        "print(\"\\n--- 5. Creating Your Specific Models (RF, MLP, SVM) ---\")\n",
        "\n",
        "print(\"Training Random Forest...\")\n",
        "rf_model = create_model('rf')\n",
        "\n",
        "print(\"Training MLP...\")\n",
        "mlp_model = create_model('mlp')\n",
        "\n",
        "print(\"Training SVM (Linear Kernel)...\")\n",
        "svm_model = create_model('svm')\n",
        "\n",
        "print(\"\\n--- All models are trained. You can now analyze them. ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Get the LightGBM Model Instance ---\n",
        "# Since PyCaret's `compare_models` already ran, this pulls the best model to a new variable.\n",
        "lightgbm_model = create_model('lightgbm')\n",
        "\n",
        "# --- 2. Plotting Performance ---\n",
        "\n",
        "# Plot 1: Area Under the Curve (AUC/ROC)\n",
        "# This confirms the model's overall ability to distinguish Attack (1) vs. Benign (0).\n",
        "print(\"\\n--- Plotting ROC Curve ---\")\n",
        "plot_model(lightgbm_model, plot='auc')\n",
        "\n",
        "# Plot 2: Confusion Matrix\n",
        "# This is CRITICAL for security: shows False Negatives (missed attacks).\n",
        "print(\"\\n--- Plotting Confusion Matrix ---\")\n",
        "plot_model(lightgbm_model, plot='confusion_matrix')\n",
        "\n",
        "# Plot 3: Feature Importance\n",
        "# Identifies which network features were most important for predicting attacks.\n",
        "print(\"\\n--- Plotting Feature Importance ---\")\n",
        "plot_model(lightgbm_model, plot='feature')"
      ],
      "metadata": {
        "id": "PBIzZs1U8PfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Save the Final Model to the Environment Folder ---\n",
        "\n",
        "# Use your actual Anaconda path as the destination:\n",
        "local_save_path = 'C:/Users/mthwm/anaconda3/envs/colab_ml_final_311/NIDS_LightGBM_Final_Model'\n",
        "\n",
        "save_model(final_ids_model, local_save_path)\n",
        "\n",
        "print(f\"\\nâœ… Final model saved successfully to: {local_save_path}.pkl\")"
      ],
      "metadata": {
        "id": "mk-7YJf3894R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}